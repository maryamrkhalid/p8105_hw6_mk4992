---
title: "p8105_hw6_mk4992"
author: "Maryam Khalid"
date: "2025-12-01"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE
)
library(tidyverse)
library(broom)
library(janitor)
library(purrr)
library(modelr)

set.seed(8105)

```

# Problem 1: Homicide Data Across U.S. Cities

The Washington Post has gathered data on over 52,000 homicides in 50 large U.S. cities over the past decade and found that across the country, there are areas where murder is common but arrests are rare.

```{r}
homicide_raw <- read_csv("data/homicide-data.csv")

homicide_raw %>%
  glimpse()

```

The raw dataset includes 52,179 homicide records from 50 large U.S. cities between the years 2007 and 2017. Each observation represents a single homicide case. The dataset contains variables describing the victim (first and last name, race, age, sex), date in which the case was first reported, location (city, state, longitude, latitude), and the status of the case (case closed by arrest, open/no arrest, case closed without arrest). 

```{r}
#DATA IMPORT AND CLEANING:
#Create city_state variable and summarize within cities to obtain total # of homicides & # of unsolved homicides
#Create binary resolution variable (1 = resolved/closed by arrest; 0 = unresolved
#Omit specific cities (Dallas, Phoenix, KC, Tulsa)
#Limit analysis to datapoints in which victim_race is white or Black
#Ensure victim_age is numeric

homicide_df <- 
  homicide_raw %>% 
  mutate(
    city_state = str_c(city, ", ", state),
    resolution = as.numeric(disposition == "Closed by arrest"),
    victim_age = as.numeric(victim_age)
  ) %>% 
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"),
    victim_race %in% c("White", "Black")
  ) %>% 
  select(city_state, resolution, victim_age, victim_sex, victim_race)

```


```{r}
#Analysis of Baltimore, MD
#Fit logistic regression model to resolve the outcome (resolved vs unresolved) based on victim age, sex, and race as predictors; use glm; save output of glm as an R object; apply the broom::tidy to this object

#Obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing male victims to female victims keeping all other variables fixed.

baltimore_glm <- 
  homicide_df %>% 
  filter(city_state == "Baltimore, MD") %>% 
  glm(resolution ~ victim_age + victim_sex + victim_race, family = binomial(), data = .)

baltimore_results <- 
  baltimore_glm %>% 
  broom::tidy(conf.int = TRUE, exponentiate = TRUE) %>% 
  filter(term == "victim_sexMale") %>% 
  select(term, estimate, conf.low, conf.high)

baltimore_results %>% 
  knitr::kable(digits = 3)



```

In Baltimore, keeping all over variables fixed, the odds of solving a homicide for a male victim are `r round(baltimore_results$estimate, 3)` times the odds of solving a homicide for a female victim.


```{r}
# Analysis: All Cities
#Run same logistic regression for each of the cities using tidy pipeline with purrr::map, list columns, and unnest as necessary to create dataframe with estimated ORs and CIs for each city
city_glm_results <- 
  homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = map(data, \(df) glm(resolution ~ victim_age + victim_sex + victim_race, 
                                family = binomial(), data = df)),
    results = map(models, \(mod) broom::tidy(mod, conf.int = TRUE, exponentiate = TRUE))
  ) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
  filter(term == "victim_sexMale") %>% 
  select(city_state, estimate, conf.low, conf.high)

head(city_glm_results)
```

```{r}
#Visualization
#Plot the estimated odds ratios and confidence intervals for each city, organized by the magnitude of the estimated OR

city_glm_results %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "red") +
  coord_flip() +
  labs(
    title = "Adjusted Odds Ratios for Solving Homicides",
    subtitle = "Comparing Male vs. Female Victims (controlled for Age and Race)",
    x = "City",
    y = "Odds Ratio (Male vs. Female)"
  ) +
  theme_minimal()
```

Th above plot shows the adjusted odds ratios (ORs) for solving homicides comparing male victims to female victims in cities across the United States.
For most cities demonstrated, the estimated OR is less than 1. This suggests that homicides involving male victims are less likely to be resolved/closed by arrest compared to those involving female victims in those cities, after accommodating for the victim's age and race.

Cities in which their error bar does not cross the dashed red line where OR = 1 have a statistically significant difference. 

New York City, NY, where we live, has the lowest estimated OR, indicating a strong disparity where female victim cases are much more likely to be solved than male victim cases. 

# Problem 2: Central Park Weather
```{r} 

#import data
library(p8105.datasets)
data("weather_df")

```


```{r}
 #Establish a simple linear regression with tmax as the response with tmin and prcp as the predictors, and are interested in the distribution of two quantities estimated from these data

#Use 5000 bootstrap samples and, for each bootstrap sample, produce estimates of these two quantities. Plot the distribution of your estimates, and describe these in words. Using the 5000 bootstrap estimates, identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval for the items

bootstrap_results <- 
  weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, \(df) lm(tmax ~ tmin + prcp, data = df)),
    
    # Extract R-squared
    results_glance = map(models, broom::glance),
    
    # Extract coefficients
    results_tidy = map(models, broom::tidy)
  ) %>% 
  select(-strap, -models) %>% 
  unnest(results_glance) %>% 
  select(.id, r.squared, results_tidy) %>% 
  unnest(results_tidy) %>% 
  select(.id, r.squared, term, estimate) %>% 
  pivot_wider(
    names_from = term, 
    values_from = estimate
  ) %>% 
  rename(
    beta_0 = `(Intercept)`,
    beta_1 = tmin,
    beta_2 = prcp
  ) %>% 
  mutate(
    # CALCULATING LOG(BETA0 * BETA1)
    log_beta0_beta1 = log(beta_0 * beta_1)
  )

head(bootstrap_results)
```

#Visualizing the Distributions
```{r}
# Plot for R-squared
p1 <- bootstrap_results %>% 
  ggplot(aes(x = r.squared)) +
  geom_density(fill = "blue", alpha = 0.5) +
  labs(
    title = "Distribution of R-squared",
    x = "Estimated R-squared",
    y = "Density"
  ) +
  theme_minimal()

# Plot for log(beta0 * beta1)
p2 <- bootstrap_results %>% 
  ggplot(aes(x = log_beta0_beta1)) +
  geom_density(fill = "green", alpha = 0.5) +
  labs(
    title = "Distribution of log(beta0 * beta1)",
    x = "log(beta0 * beta1)",
    y = "Density"
  ) +
  theme_minimal()

# Display plots side-by-side
library(patchwork)
p1 + p2
```

The distribution of r^2 is approximately normal with a slight skew towards the right, centered around 0.943, indicating that tmin and prcp consistently explain a large proportion of the variance in maximum temperature across the bootstrap samples. 
The distribution of log(beta_0 * beta_1) also appears to be normally distributed, suggesting that the estimates for this quantity are stable and follow a standard bell curve shape.


```{r}
ci_results <- 
  bootstrap_results %>% 
  summarize(
    ci_lower_r2 = quantile(r.squared, 0.025),
    ci_upper_r2 = quantile(r.squared, 0.975),
    
    ci_lower_log = quantile(log_beta0_beta1, 0.025),
    ci_upper_log = quantile(log_beta0_beta1, 0.975)
  )

ci_results %>% 
  knitr::kable(digits = 3)
```

# Problem 3: Child's Birthweight
```{r} 
#Load and clean the data for regression analysis (i.e. use appropriate variable names, convert numeric to factor where appropriate, check for the presence of missing data, etc.).

birthweight_df <- 
  read_csv("data/birthweight.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    babysex = factor(babysex, levels = c(1, 2), labels = c("Male", "Female")),
    frace = factor(frace, levels = c(1, 2, 3, 4, 8, 9), 
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other", "Unknown")),
    mrace = factor(mrace, levels = c(1, 2, 3, 4, 8), 
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other")),
    malform = factor(malform, levels = c(0, 1), labels = c("Absent", "Present"))
  )

# Check for missing data
missing_data_summary <- map_df(birthweight_df, ~sum(is.na(.)))
print(missing_data_summary)


```

HYPOTHESIS: birthweight is likely influenced by: 
- biological factors: gestational age (gaweeks), mother's height (mheight), and mother's pre-pregnancy BMI (ppbmi)
- behavioral factors: cigarettes smoked during pregnancy (smoken)
- demographic factors: mother's race (mrace)

```{r} 
#Propose a regression model for birthweight. This model may be based on a hypothesized structure for the factors that underly birthweight, on a data-driven model-building process, or a combination of the two. Describe your modeling process and show a plot of model residuals against fitted values â€“ use add_predictions and add_residuals in making this plot.

proposed_model <- lm(bwt ~ gaweeks + mheight + ppbmi + smoken + mrace, data = birthweight_df)

# Add predictions and residuals, then plot
birthweight_df %>% 
  add_predictions(proposed_model) %>% 
  add_residuals(proposed_model) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(
    title = "Residuals vs. Fitted Values (Proposed Model)",
    x = "Fitted Values (Predicted Birthweight)",
    y = "Residuals"
  ) +
  theme_minimal()


```
 
 The residuals are relatively symmetrically distributed around the horizontal line at y = 0 for the majority of the data range (fitted values ranging primarily between 2000g and 4000g). This suggests the linear model captures the central tendency of the data reasonably well. The noticeable outliers on the left end may represent babies that were premature at birth or those with medical complications that would explain a lower weight.

 
Compare my proposed model against:
1) main effects model: length at birth (blength) and gestational age (gaweeks)
2) interaction model: head circumference, length, sex, and all possible interactions

I utilize Monte Carlo cross-validation (crossv_mc) with 100 splits to calculate RMSE for each model
```{r} 
#Compare your model to two others:
#One using length at birth and gestational age as predictors (main effects only)
#One using head circumference, length, sex, and all interactions (including the three-way interaction) between these
#Make this comparison in terms of the cross-validated prediction error; use crossv_mc and functions in purrr as appropriate.
# Create cross-validation splits
cv_df <- 
  crossv_mc(birthweight_df, n = 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )

# Fit models and calculate RMSE
cv_results <- 
  cv_df %>% 
  mutate(
    # Model 1: My Proposed Model
    mod_proposed = map(train, \(df) lm(bwt ~ gaweeks + mheight + ppbmi + smoken + mrace, data = df)),
    
    # Model 2: Length and Gestational Age (Main Effects)
    mod_main = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    
    # Model 3: Head Circumference, Length, Sex (Interactions)
    mod_interaction = map(train, \(df) lm(bwt ~ bhead * blength * babysex, data = df))
  ) %>% 
  mutate(
    rmse_proposed = map2_dbl(mod_proposed, test, \(mod, df) rmse(mod, df)),
    rmse_main = map2_dbl(mod_main, test, \(mod, df) rmse(mod, df)),
    rmse_interaction = map2_dbl(mod_interaction, test, \(mod, df) rmse(mod, df))
  )

# Visualize the comparison
cv_results %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  mutate(model = fct_reorder(model, rmse)) %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_violin(aes(fill = model), alpha = 0.5) +
  labs(
    title = "Cross-Validated RMSE Comparison",
    x = "Model",
    y = "RMSE"
  ) +
  theme_minimal()

```

The violin plot establishes a clear hierarchy in the models' performances based on the RMSE.
The best model is the interaction model, which includes head circumference, length, sex, and all interactions, as it has the lowest RMSE. This model is most accurate at predicting birthweight.This makes fundamental sense as it uses variables that are direct physical measures of the baby at birth.

The next best model is the main effects model, which uses only birth length and gestational age. It makes sense that this model performs decently as there is a direct physical measure from the baby (the length/height, which is a part of the 'volume' of the baby) and the gestational age (one expects a premature baby to be underweight).

My proposed model was unforunately the weakest, as it relied on the mother's characteristics i.e. age, race, smoking status, etc. This model had the highest RMSE. While these factors are certainly relevant to the risk of being outside of ideal birthweight (ex: smoking during pregnancy is an obviously detrimental factor to gestational development, which could lead to lower birthweight), they are not as accurate in predicting the exact birthweight in grams of a baby compared to direct measurements of the baby. 




